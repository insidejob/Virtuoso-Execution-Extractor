# üéØ Execution Data vs Journey Data - Complete Comparison

## Overview: Two Different Types of Data

### Journey Data (TestSuite Definition)
**What**: The test blueprint/template
**When**: Created during test design
**Purpose**: Defines what should be tested

### Execution Data
**What**: Actual test run results
**When**: Generated during test execution
**Purpose**: Shows what actually happened

## üìä Side-by-Side Comparison

| Aspect | Journey Data | Execution Data |
|--------|--------------|----------------|
| **URL Pattern** | `/journey/527286` | `/execution/86339/journey/527257` |
| **API Endpoint** | `GET /testsuites/527286` | `GET /executions/86339` |
| **Content Type** | Static definition | Dynamic results |
| **Changes** | Only when edited | Every execution |
| **Primary Value** | Test structure | Test outcomes |

## üîç Data Content Comparison

### Journey Data Contains:
```json
{
  "steps": [
    {
      "action": "click",
      "selector": "#button",
      "description": "Click login button"
    }
  ]
}
```

### Execution Data Contains:
```json
{
  "steps": [
    {
      "action": "click",
      "selector": "#button",
      "status": "failed",
      "duration": 1234,
      "error": "Element not found",
      "screenshot": "failure_123.png",
      "timestamp": "2025-01-10T14:23:45Z"
    }
  ]
}
```

## üöÄ Key Differences in Information

### 1. **Status Information**
- **Journey**: No status (it's a template)
- **Execution**: Pass/Fail/Skipped for each step

### 2. **Timing Data**
- **Journey**: Expected timeouts
- **Execution**: Actual execution times

### 3. **Error Details**
- **Journey**: None
- **Execution**: Detailed error messages, stack traces, AI analysis

### 4. **Visual Evidence**
- **Journey**: None
- **Execution**: Screenshots, videos, DOM snapshots

### 5. **Performance Metrics**
- **Journey**: None
- **Execution**: Page load times, network requests, resource usage

## üìà Benefits of Each Data Type

### Journey Data Benefits:
1. **Consistency** - Same structure always
2. **Planning** - See test design intent
3. **Editing** - Understand what to modify
4. **Documentation** - Serves as test documentation

### Execution Data Benefits:
1. **Debugging** - See exactly what failed and why
2. **Performance** - Actual timing and resource data
3. **History** - Compare with previous runs
4. **Evidence** - Screenshots and logs for proof
5. **AI Analysis** - Smart failure explanations

## üéØ When to Use Each

### Use Journey Data When:
- Setting up new tests
- Understanding test structure
- Modifying test steps
- Documentation purposes
- Training team members

### Use Execution Data When:
- Debugging failures
- Analyzing performance
- Reporting test results
- Investigating flaky tests
- Proving test coverage

## üí° Real-World Example

### Scenario: Login Test Fails

**Journey Data Shows:**
```
Step: Click button with selector "#login-button"
```

**Execution Data Shows:**
```
Step: Click button with selector "#login-button"
Status: FAILED
Duration: 10,000ms (timeout)
Error: Element not found
AI Analysis: Button selector changed to "#signin-button"
Screenshot: Shows actual page state
Suggestion: Update selector to "#signin-button"
Console Error: TypeError at login.js:45
Network: 404 error on /api/auth
```

## üîÑ Complete Data Extraction Strategy

### For Comprehensive Analysis:
1. **Get Journey Structure**: Understand what should happen
2. **Get Execution Results**: See what actually happened
3. **Compare**: Identify discrepancies
4. **Analyze**: Use AI insights to fix issues

### API Calls Needed:
```bash
# 1. Get journey definition
GET /testsuites/527257

# 2. Get execution results
GET /executions/86339

# 3. Get failure analysis
POST /executions/86339/failures/explain

# 4. Get performance metrics
GET /executions/86339/metrics
```

## üìä Execution Data Exclusive Features

### 1. **AI-Powered Failure Analysis**
```json
{
  "aiAnalysis": {
    "rootCause": "Selector changed",
    "suggestion": "Update to new selector",
    "confidence": 0.87,
    "autoHealAvailable": true
  }
}
```

### 2. **Historical Context**
```json
{
  "previousExecutions": [
    { "id": 86338, "status": "passed" },
    { "id": 86337, "status": "passed" }
  ],
  "firstFailure": "2025-01-10T14:23:00Z",
  "pattern": "New failure - was passing"
}
```

### 3. **Performance Trending**
```json
{
  "performance": {
    "currentLoadTime": 2145,
    "averageLoadTime": 1650,
    "degradation": "+30%"
  }
}
```

### 4. **Network Analysis**
```json
{
  "networkErrors": [
    {
      "url": "/api/dashboard",
      "status": 500,
      "impact": "Dashboard widgets failed to load"
    }
  ]
}
```

## üéØ The Power of Execution Data

### Execution data answers:
1. **Why did it fail?** - Detailed error messages
2. **When did it fail?** - Exact timestamps
3. **What was the state?** - Screenshots and DOM
4. **How can I fix it?** - AI suggestions
5. **Is it getting worse?** - Historical trends
6. **What else failed?** - Related failures
7. **How fast was it?** - Performance metrics

### Journey data only answers:
1. **What should happen?** - Test steps
2. **What to check?** - Assertions
3. **What order?** - Step sequence

## ‚úÖ Conclusion

**Journey Data** = Test Definition (The Plan)
**Execution Data** = Test Results (What Happened)

For debugging and analysis, **execution data is 10x more valuable** because it contains:
- Real results
- Actual timings
- Error details
- Screenshots
- AI analysis
- Performance metrics
- Historical context

While journey data shows the test structure, execution data shows the test reality - making it essential for understanding and fixing test failures.